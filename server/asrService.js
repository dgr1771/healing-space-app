/**
 * è¯­éŸ³è¯†åˆ«æœåŠ¡ - ä½¿ç”¨ Transformers.js æœ¬åœ°è¿è¡Œ Whisper æ¨¡å‹
 * æ”¯æŒï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR)ï¼Œæ— éœ€å¤–éƒ¨API
 */

import { pipeline, env } from '@xenova/transformers'

// ç¦ç”¨æœ¬åœ°æ¨¡å‹æ£€æŸ¥ï¼Œä»HuggingFace Hubä¸‹è½½
env.allowLocalModels = false
env.allowRemoteModels = true

class ASRService {
  constructor() {
    this.transcriber = null
    this.isModelLoaded = false
    this.initializing = false
  }

  /**
   * åˆå§‹åŒ–Whisperæ¨¡å‹
   */
  async initialize() {
    if (this.isModelLoaded) {
      return
    }

    if (this.initializing) {
      // å¦‚æœæ­£åœ¨åˆå§‹åŒ–ï¼Œç­‰å¾…å®Œæˆ
      while (this.initializing) {
        await new Promise(resolve => setTimeout(resolve, 100))
      }
      return
    }

    try {
      this.initializing = true
      console.log('ğŸ¤ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½ï¼Œçº¦74MBï¼‰...')

      // ä½¿ç”¨ Xenova çš„ Whisper Tiny æ¨¡å‹ï¼ˆæœ€å°æœ€å¿«ï¼‰
      this.transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny')

      console.log('âœ… Whisper æ¨¡å‹åŠ è½½æˆåŠŸ')
      this.isModelLoaded = true
    } catch (error) {
      console.error('âŒ Whisper æ¨¡å‹åŠ è½½å¤±è´¥:', error)
      throw new Error('è¯­éŸ³è¯†åˆ«æ¨¡å‹åˆå§‹åŒ–å¤±è´¥')
    } finally {
      this.initializing = false
    }
  }

  /**
   * è¯†åˆ«éŸ³é¢‘ï¼ˆBase64æ ¼å¼ï¼‰
   * @param {string} base64Audio - Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
   * @param {string} mimeType - éŸ³é¢‘MIMEç±»å‹
   * @returns {Promise<{text: string, confidence: number}>}
   */
  async transcribe(base64Audio, mimeType = 'audio/webm') {
    if (!this.isModelLoaded) {
      await this.initialize()
    }

    try {
      // å°†Base64è½¬æ¢ä¸ºFloat32Array
      const audioData = this.base64ToAudioData(base64Audio)

      // è°ƒç”¨Whisperè¿›è¡Œè¯†åˆ«
      const result = await this.transcriber(audioData, {
        chunk_length_s: 30,
        stride_length_s: 5,
        language: 'chinese', // ä¼˜å…ˆè¯†åˆ«ä¸­æ–‡
        task: 'transcribe',
        return_timestamps: false,
      })

      return {
        text: result?.text?.trim() || '',
        confidence: 0.95, // Transformers.jsä¸æä¾›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨å›ºå®šå€¼
      }
    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * æ‰¹é‡è¯†åˆ«æ¢¦è¯äº‹ä»¶
   * @param {Array} events - æ¢¦è¯äº‹ä»¶æ•°ç»„
   * @returns {Promise<Array>} è¯†åˆ«åçš„äº‹ä»¶æ•°ç»„
   */
  async transcribeEvents(events) {
    const results = []

    for (let i = 0; i < events.length; i++) {
      const event = events[i]

      // åªå¤„ç†æ¢¦è¯äº‹ä»¶ä¸”æœ‰éŸ³é¢‘æ•°æ®çš„äº‹ä»¶
      if (event.type === 'sleep_talking' && event.audioData && !event.transcript) {
        try {
          console.log(`ğŸ¤ è¯†åˆ«æ¢¦è¯ ${i + 1}/${events.length}...`)

          const result = await this.transcribe(event.audioData, 'audio/webm')

          results.push({
            ...event,
            transcript: result.text || '(æœªèƒ½è¯†åˆ«)',
          })

          console.log(`âœ… è¯†åˆ«å®Œæˆ: "${result.text.substring(0, 30)}${result.text.length > 30 ? '...' : ''}"`)
        } catch (error) {
          console.error(`âŒ æ¢¦è¯ ${i + 1} è¯†åˆ«å¤±è´¥:`, error.message)
          results.push({
            ...event,
            transcript: '(è¯†åˆ«å¤±è´¥)',
          }) // æ ‡è®°è¯†åˆ«å¤±è´¥ä½†ä¿ç•™äº‹ä»¶
        }
      } else {
        results.push(event)
      }
    }

    return results
  }

  /**
   * Base64è½¬æ¢ä¸ºéŸ³é¢‘æ•°æ®ï¼ˆFloat32Arrayï¼‰
   * æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…ä½¿ç”¨å¯èƒ½éœ€è¦æ›´å¤æ‚çš„éŸ³é¢‘è§£ç 
   */
  base64ToAudioData(base64Data) {
    // ç”±äºwebmæ ¼å¼è§£ç è¾ƒå¤æ‚ï¼Œè¿™é‡Œè¿”å›åŸå§‹éŸ³é¢‘URLä¾›æ¨¡å‹å¤„ç†
    // Transformers.jsæ”¯æŒä»URLåŠ è½½éŸ³é¢‘
    return `data:audio/webm;base64,${base64Data}`
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
   */
  isReady() {
    return this.isModelLoaded
  }

  /**
   * è·å–æ¨¡å‹çŠ¶æ€
   */
  getStatus() {
    return {
      isReady: this.isModelLoaded,
      isInitializing: this.initializing,
      modelName: 'Xenova/whisper-tiny',
    }
  }
}

export const asrService = new ASRService()
